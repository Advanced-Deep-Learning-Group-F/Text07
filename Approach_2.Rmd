---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.11.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Iterative Registration

The approach of estimating the Transformation Matrix isn't easily applicable to the real world because normally the input data for image registration problems are images rather than the point pairs. To be able to work directly with images other approaches are needed. One such approach utilizes Deep Reinforcement Learning and is called Iterative Registration.

The idea behind this approach is to train an artificial agent to mimick how a human expert would solve the problem of aligning images. This changes the problem from a regression task to a classification task in which the agent chooses one action at a time to iteratively align the images, hence the name of this approach.

## Procedure

The approach was first used in a medical context and opperated on 3-dimensional image data. The dataset consisted of image pairs that had to be registred. The second image of these pairs were created by applying a randomly generated transformation matrix to the original image. The agent should then learn to transform the second image back to the original one.

The actions the agent can take are:
- positive rotation around x, y and z axis
- negative rotation around x, y and z axis
- positive translation in x, y and z direction
- negative translation in x, y and z direction

Each action can be represented as a transformation matrix that gets applied to the image. The neural network is then trained to find the action that would minimize the distance to the true transformation matrix which would yield the highest reward.

During training the true transformation matrix is known because it was used in the generation of the dataset.    
The network takes two images as its input and from these predicts the reward each action would yield. The action, giving the maximal reward, is then applied to the second image. Together with the original image, the resulting image is then again fed into the network to predict the next action.  

## Network structure

The network that was used for this approach had 5 convolutional layers followed by 3 fully connected layers and 12 output neurons one for each possible action.
