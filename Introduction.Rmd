---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.11.2
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Image Registration


So far we have covered the history of deep architectures for image classification tasks, how neural architectures can be designed. We learned about how classification losses can be derived and understood and how in Similarity Learning, the objective is framed differently, in that we want to push related feature embeddings closer together and (supposedly) unrelated embeddings further apart. We went on to learn about how the task of Object Detection can be framed. 

In this chapter, we will go on to learn about yet another topic in deep learning, which is image registration. We first define the problem faced in Image Registration, which tasks we are concerned with in Image Registration and introduce the concept of transformation matrices. We will go on to examine three different approaches to Image Registration in historical order: 

- Transformation matrix estimation, 
- Iterative Registration
- Joint Detection and Description with Deep Features




## What is Image Registration?

In an Image Registration task, we want to **align images** that are taken from **different perspectives** or have **different distortions**. We generally assume that we have at least two images that depict the same objects or the same scene.

We will now give and explain some example use-cases of such an alignment of images:

<!-- #region -->
- In HDR (High Dynamic Range) photography, we're interested in increasing the dynamic range (i.e. the brightness steps) of an image by combining multiple images taken with a different aperture. Details that are blown out due to overexposure in one image can be exposed just correctly in another image. Combining these images can help having an equal amount of detail in shadows as well as close to light sources and reflections. To utilize this idea, the images must first be aligned, because we don't usually have a static scene and camera.
<img src="images/HDR_new_layout.png" width="100%" height="100%" style="padding-top:15px"/>


- In Focus stacking we want to combine images with different focuses to obtain an image in which the depth of field is maximal and everything is in focus. For this too, we need to have the images aligned.
<img src="images/focus_stacking.png" width="75%" height="75%" style="padding-top:15px"/>


- Similarly to stacking focus, we can use multiple images to increase the signal to noise ratio in an image (i.e. make invisible structure visible by combining multiple signals).
<img src="images/signal_to_noise.png" width="55%" height="55%" style="padding-top:15px"/>


- In Medical imaging (e.g. MRI), images need to be aligned to facilitate comparison between different subjects or between different images of the same subject at different times.
<img src="images/mri.png" width="40%" height="40%" style="padding-top:15px"/>


- In panorama or 360° photography, we want to stack images taken from different angles and positions to obtain a seamless image covering a larger area. An example of this is Google Maps' Street View. We also call this process Image Stitching
<img src="images/stitching.png" width="50%" height="50%" style="padding-top:15px"/>


- In repeat photography, we want to align historical images with contemporary images to compare how a place has changed throughout history.
<img src="images/repeat.png" width="50%" height="50%" style="padding-top:15px"/>


- Scene reconstruction is a bit different from the previous examples in that we don't align a taken image with another image but a 3D scene with an image.


- In Motion tracking, we again have a non-static scene (objects depicted and/or camera) and estimate how much and in which direction objects or the camera have been moved. This is utilized in making actors control the movement of creatures that are rendered with some 3D software.


- Stabilizing a video taken by a non-static camera can also be interpreted as aligning images. 
<br><br>

We see that the use of image registration techniques is already pretty common (even without VR and AR technologies playing a central role in our lives).

But how do we actually align images?
<!-- #endregion -->

<!-- #region -->
## Global vs Local Transformations
Imagine yourself with two images each taken from a different perspective. One of them lays infront of you on a table the other one you hold with both of your hands. Lets also say that the image in your hands is somewhat transparent to make it easier. How would you align the image in your hands to the image on the table?
<br>

The first thing you might do is move the image roughly above the image on the table so that their positions somewhat match up.<br>
If we abstract our image into the realm of mathematics then we can think of the image as in a 2d space<br>
and we can interpret its movement as a shift along the x or y-axis. <br>
To achieve these kind of shifts we shift the whole 2d space and with it will go the image as a subset of this space. To transform our 2d space in general we can use our favourite thing, matrices.<br>
If you are unsure about why matrices represent transformations we recommend [this video](https://www.youtube.com/watch?v=kYB8IZa5AuE). <br>
The thing is that matrices will only transform our space linearly, meaning the origin will stay fixed and parallel lines will remain parallel. Parallel lines staying parallel sounds good, but to achieve a shift we will also have to move the origin.<br>

To adress this issue we can  switch to affine transformations<br>
You can think of affine transformations as doing a linear transformation but then adding a vector on top.
<br>

$$f(x) = Ax + b$$
<br>

$$\begin{pmatrix}5\\3\end{pmatrix} = \begin{bmatrix}2 & 0 \\ 0 & 2\end{bmatrix} \centerdot \begin{pmatrix}2\\1\end{pmatrix} + \begin{pmatrix}1\\1\end{pmatrix}$$

So we can transform our image linearly with *matrix* $A$ and also shift it along the x or y-axis with *vector* $b$.<br>
*To get the name of the transformations hover over the gifs*
<img title="Translation" src="gifs/simple_translate.gif" width="30%" height="30%"/>



For our hands on example that means we can now roughly match the positions by shifting the image and we can also do everything that keeps parallel lines parallel, think of the edges staying parallel.<br>
So for example we can rotate our image or squezze or stretch it from oposing sides, given that the material allows for it.<br>
*The blue grid represents the old space without a transformation applied*
<table><tr>
<td> <img title="Rotation" src="gifs/rotation.gif" width="50%" height="50%"/> </td>
<td> <img title="Stretching" src="gifs/stretching.gif" width="50%" height="50%"/> </td> 
</tr></table>
 









Now the question arises, is there anything that we can with the image in our hands that is not described by affine transformations

 
<!-- #endregion -->

<!-- #region -->
## Global Transformation Matrices

When aligning two images in Image Registration, we assume that one image is a transformed version of the other image. 

In *rigid* registration we assume that the transformation can be described by a global transformation (comprising rotation, translation as well as affine or projective transformations). *Non-rigid* Image Registration on the other hand does not assume a global transformation having taken place but a local distortion. This might be useful for un-distorting pictures taken with a lens that has a distortion but in this chapter we will focus on rigid Image Registration.

A global transformation in rigid Registration can be described by a transformation matrix. 
In the following we will present




But how can we get a transformation matrix that aligns two images from different perspectives in a satisfying manner
<!-- #endregion -->

<!-- #region -->
# Approach 1

To understand the first approach, we must understand how an image can be rotated, translated, projected, sheared, scaled etc. with transformation matrices. For this purpose, we give two examples for rotation and translation and provide a link to resources about other transformations.

Affine transformations have the property of preserving lines and their parallelity. Translation, scaling, homothety, similarity, reflection, rotation, shear mapping, and compositions of them in any combination and sequence belong to affine transformations.

While affine transformations preserve parallel lines, projective transformations in projective geometry do not preserve parallel lines. Projective transformations can be best thought of as changing the perspective/viewpoint.

"Approach 1" is concerned with learning affine transformations.

### example 1: translation
An example for translation, another example for rotation and another one for projective transformation (slide 55, but in LaTeX with nice matrix representation and two images)
![image.png](attachment:image.png)
<img src="gifs/translate_transformation.gif" width="50%" height="50%"/>


### example 2: rotation

- x
<!-- #endregion -->
### Gifs
![SegmentLocal](gifs/LinearTransformation.gif "segment")








```{python}
 
```
